{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Adult Dataset\n",
    "https://archive.ics.uci.edu/ml/datasets/Adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read dataset\n",
    "df_adult = pd.read_csv('datasets/original/adult_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adult.columns = ['age', 'workclass', 'fnlwgt', 'education', 'education_num', 'marital-status', 'occupation',\n",
    "                    'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country',\n",
    "                    'salary']\n",
    "\n",
    "#df_adult.replace({'?': np.nan}).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "education_? does not exist.\n",
      "marital-status_? does not exist.\n",
      "relationship_? does not exist.\n",
      "race_? does not exist.\n",
      "sex_? does not exist.\n",
      "salary_? does not exist.\n"
     ]
    }
   ],
   "source": [
    "## Apply one hot encoding to categorical attributes\n",
    "categorical_attributes = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
    "                          'native-country', 'salary']\n",
    "\n",
    "for categorical_attribute in categorical_attributes:\n",
    "    \n",
    "    ## Strip white space while encoding\n",
    "    one_hot = pd.get_dummies(df_adult[categorical_attribute].str.strip(), prefix=categorical_attribute)\n",
    "    \n",
    "    ## Drop columns that are encoded for unknown values\n",
    "    try:\n",
    "        one_hot = one_hot.drop([categorical_attribute + '_?'], axis=1)\n",
    "    except:\n",
    "        print(categorical_attribute + '_? does not exist.')\n",
    "    \n",
    "    ## Replace original column with encoded columns\n",
    "    df_adult = df_adult.drop([categorical_attribute], axis=1)\n",
    "    df_adult = pd.concat([df_adult, one_hot], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop the target column 'salary_<=50K' because 'salary_>50K' alone is enough\n",
    "df_adult = df_adult.drop(['salary_<=50K'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalize data in each column\n",
    "x = df_adult.values\n",
    "attributes = df_adult.columns.values\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "df_adult = pd.DataFrame(x_scaled)\n",
    "df_adult.columns = attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save cleaned dataset\n",
    "df_adult.to_csv('datasets/cleaned/adult_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Occupancy Dataset\n",
    "https://archive.ics.uci.edu/ml/datasets/Occupancy+Detection+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read dataset\n",
    "df_occupancy_train = pd.read_csv('datasets/original/occupancy/occupancy_train.csv')\n",
    "df_occupancy_test1 = pd.read_csv('datasets/original/occupancy/occupancy_test1.csv')\n",
    "df_occupancy_test2 = pd.read_csv('datasets/original/occupancy/occupancy_test2.csv')\n",
    "df_occupancy = pd.concat([df_occupancy_train, df_occupancy_test1, df_occupancy_test2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop 'data' column\n",
    "df_occupancy = df_occupancy.drop(['date'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalize data in each column\n",
    "x = df_occupancy.values\n",
    "attributes = df_occupancy.columns.values\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "df_occupancy = pd.DataFrame(x_scaled)\n",
    "df_occupancy.columns = attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save cleaned dataset\n",
    "df_occupancy.to_csv('datasets/cleaned/occupancy_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean HTRU2 Dataset\n",
    "https://archive.ics.uci.edu/ml/datasets/HTRU2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read dataset\n",
    "df_HTRU2 = pd.read_csv('datasets/original/HTRU2_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ip -> integrated profile; ds -> DM-SMR curve\n",
    "df_HTRU2.columns = ['ip_mean', 'ip_standard_deviation', 'ip_excess_kurtosis', 'ip_skewness',\n",
    "                    'ds_mean', 'ds_standard_deviation', 'ds_excess_kurtosis', 'ds_skewness', 'is_pulsar']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalize data in each column\n",
    "x = df_HTRU2.values\n",
    "attributes = df_HTRU2.columns.values\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "df_HTRU2 = pd.DataFrame(x_scaled)\n",
    "df_HTRU2.columns = attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save cleaned dataset\n",
    "df_HTRU2.to_csv('datasets/cleaned/HTRU2_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Activity Dataset\n",
    "https://archive.ics.uci.edu/ml/datasets/Activity+recognition+with+healthy+older+people+using+a+batteryless+wearable+sensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read dataset\n",
    "\n",
    "## Attribute encoding\n",
    "#  time -> Time in seconds\n",
    "#  acc_f -> Acceleration reading in G for frontal axis\n",
    "#  acc_v -> Acceleration reading in G for vertical axis\n",
    "#  acc_l -> Acceleration reading in G for lateral axis\n",
    "#  sensor_id -> Id of antenna reading sensor\n",
    "#  rssi -> Received signal strength indicator (RSSI)\n",
    "#  phase -> Phase\n",
    "#  frequency -> Frequency\n",
    "#  activity -> Label of activity, 1: sit on bed, 2: sit on chair, 3: lying, 4: ambulating\n",
    "\n",
    "activity_dataset_path = 'datasets/original/activity/S1_Dataset'\n",
    "activity_dataset_files = glob.glob(activity_dataset_path + \"/*.csv\")\n",
    "\n",
    "dfs_activity = []\n",
    "\n",
    "for activity_dataset_file in activity_dataset_files:\n",
    "    df_activity = pd.read_csv(activity_dataset_file, header=None)\n",
    "    dfs_activity.append(df_activity)\n",
    "    \n",
    "df_activity = pd.concat(dfs_activity, axis=0, ignore_index=True)\n",
    "df_activity.columns = ['time', 'acc_f', 'acc_v', 'acc_l', 'sensor_id', 'rssi', 'phase', 'frequency', 'activity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop 'time' column\n",
    "df_activity = df_activity.drop(['time'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Apply one hot encoding to categorical attributes\n",
    "categorical_attributes = ['sensor_id', 'activity']\n",
    "\n",
    "for categorical_attribute in categorical_attributes:\n",
    "\n",
    "    one_hot = pd.get_dummies(df_activity[categorical_attribute], prefix=categorical_attribute)\n",
    "    \n",
    "    ## Replace original column with encoded columns\n",
    "    df_activity = df_activity.drop([categorical_attribute], axis=1)\n",
    "    df_activity = pd.concat([df_activity, one_hot], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop 'activity_1', 'activity_2', and 'activity_3' to make this a binary classification dataset.  \n",
    "##   And since we are more interested in whether the person is moving, we keep 'activity_4' as \n",
    "##   the binary classification label. \n",
    "df_activity = df_activity.drop(['activity_1', 'activity_2', 'activity_3'], axis=1)\n",
    "\n",
    "## Rename 'activity_4' to 'is_ambulating'\n",
    "df_activity = df_activity.rename(columns={'activity_4': 'is_ambulating'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalize data in each column\n",
    "x = df_activity.values\n",
    "attributes = df_activity.columns.values\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "df_activity = pd.DataFrame(x_scaled)\n",
    "df_activity.columns = attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save cleaned dataset\n",
    "df_activity.to_csv('datasets/cleaned/activity_cleaned.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
